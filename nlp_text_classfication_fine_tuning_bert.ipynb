{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3CbOywpU5ck"
      },
      "source": [
        "# Text Classification with Fine Tuning Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcM-0RterS4"
      },
      "source": [
        "## **Cek resource & Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2ir5JFA-htd",
        "outputId": "1554e156-27f2-4c2e-9d3e-e270734dba3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "there are 1 GPU(s) available.\n",
            "we will use the GPU:  Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "\n",
        "  print('there are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "  print('we will use the GPU: ', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "  print(\"No GPU available, using the CPU instead\")\n",
        "  device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fU3axooe-T5"
      },
      "source": [
        "## **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h3TeNKSAZnE",
        "outputId": "18618aad-24f2-4119-f29f-bf9bcf60a48c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21601, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df_dev = pd.read_csv('data/dev.csv')\n",
        "df_test = pd.read_csv('data/test.csv')\n",
        "df_train = pd.read_csv('data/train.csv')\n",
        "\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0lDo0_u8UXCk",
        "outputId": "fbcc8545-3b49-4e5a-8914-fdeea4aa888a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2844f5af-8965-494f-ad0a-728f4fed3525\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13276</th>\n",
              "      <td>13276</td>\n",
              "      <td>short little clip for da memes like and follow...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11145</th>\n",
              "      <td>11145</td>\n",
              "      <td>emg main twitter wajib jbjb mutual ya yahh gw ...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19109</th>\n",
              "      <td>19109</td>\n",
              "      <td>penyampaian menkes terkesan santai headline me...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5945</th>\n",
              "      <td>5945</td>\n",
              "      <td>teknologi berkomunikasi memaksimalkan physical...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9638</th>\n",
              "      <td>9638</td>\n",
              "      <td>dennysiregar7 kpai official ya gini sih susah ...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2844f5af-8965-494f-ad0a-728f4fed3525')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2844f5af-8965-494f-ad0a-728f4fed3525 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2844f5af-8965-494f-ad0a-728f4fed3525');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                             text_a label\n",
              "13276       13276  short little clip for da memes like and follow...    no\n",
              "11145       11145  emg main twitter wajib jbjb mutual ya yahh gw ...    no\n",
              "19109       19109  penyampaian menkes terkesan santai headline me...    no\n",
              "5945         5945  teknologi berkomunikasi memaksimalkan physical...   yes\n",
              "9638         9638  dennysiregar7 kpai official ya gini sih susah ...   yes"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffHeSZGbUscX"
      },
      "source": [
        "## **Label Encoder**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_JieqwfKU6is",
        "outputId": "7da5cd6a-323c-4b08-9be0-c02fb3701bb1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-1518b1ca-72d2-4d22-9f4d-8ca0f08380de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "      <th>worth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17270</th>\n",
              "      <td>17270</td>\n",
              "      <td>rekrutmen cpns pppk ditiadakan</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14599</th>\n",
              "      <td>14599</td>\n",
              "      <td>silaturahmi fitri physical distancing https t ...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7992</th>\n",
              "      <td>7992</td>\n",
              "      <td>putraerlangga trirismaharini lho ssuai kpasita...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20323</th>\n",
              "      <td>20323</td>\n",
              "      <td>ghost konslet kasih tau menhub beliau kena corona</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11631</th>\n",
              "      <td>11631</td>\n",
              "      <td>asknonym iya bener virus disekitar cuman karna...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1518b1ca-72d2-4d22-9f4d-8ca0f08380de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1518b1ca-72d2-4d22-9f4d-8ca0f08380de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1518b1ca-72d2-4d22-9f4d-8ca0f08380de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                             text_a label  \\\n",
              "17270       17270                     rekrutmen cpns pppk ditiadakan   yes   \n",
              "14599       14599  silaturahmi fitri physical distancing https t ...    no   \n",
              "7992         7992  putraerlangga trirismaharini lho ssuai kpasita...    no   \n",
              "20323       20323  ghost konslet kasih tau menhub beliau kena corona   yes   \n",
              "11631       11631  asknonym iya bener virus disekitar cuman karna...    no   \n",
              "\n",
              "       worth  \n",
              "17270      1  \n",
              "14599      0  \n",
              "7992       0  \n",
              "20323      1  \n",
              "11631      0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['worth'] = df_train['label'].apply(lambda x : 1 if x=='yes' else 0)\n",
        "df_train.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Yu5TdwiEUqmT",
        "outputId": "fdd4ef3c-45db-43c3-cb69-352d0e0f29e7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bea1922f-0c50-40db-8e3c-fb31cac0d9a7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "      <th>worth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>hoaks pasien korona di indonesia</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2363</th>\n",
              "      <td>kemaren kerja deket tv client denger menkes ng...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>kapansi covid 19 berhenti menyebar menghilang ...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1449</th>\n",
              "      <td>gadai cepat wa 0812 1800 9839 gadai rumah sert...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>656</th>\n",
              "      <td>e100ss spt nya menkes sesuai panduan who https...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bea1922f-0c50-40db-8e3c-fb31cac0d9a7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bea1922f-0c50-40db-8e3c-fb31cac0d9a7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bea1922f-0c50-40db-8e3c-fb31cac0d9a7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 text_a label  worth\n",
              "220                    hoaks pasien korona di indonesia   yes      1\n",
              "2363  kemaren kerja deket tv client denger menkes ng...    no      0\n",
              "196   kapansi covid 19 berhenti menyebar menghilang ...    no      0\n",
              "1449  gadai cepat wa 0812 1800 9839 gadai rumah sert...    no      0\n",
              "656   e100ss spt nya menkes sesuai panduan who https...    no      0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_test['worth'] = df_test['label'].apply(lambda x : 1 if x=='yes' else 0)\n",
        "df_test.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3xjZa_qjfj3r",
        "outputId": "ae7cabdd-8dbf-4510-dca8-cc3c98018b31"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-025150d8-7e64-4bfe-8107-914ffd9fc477\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "      <th>worth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2075</th>\n",
              "      <td>fadlizon matanajwa najwashihab fadjroel jokowi...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>989</th>\n",
              "      <td>fikrii509 musim ujan bjir takut kena virus corona</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>grosir masker spirulina depok sms wa 082258435...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>ramayanads ezash ramayana aja min depok graha ...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1696</th>\n",
              "      <td>anies baswedan bentuk tim khusus posko tanggap...</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-025150d8-7e64-4bfe-8107-914ffd9fc477')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-025150d8-7e64-4bfe-8107-914ffd9fc477 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-025150d8-7e64-4bfe-8107-914ffd9fc477');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                 text_a label  worth\n",
              "2075  fadlizon matanajwa najwashihab fadjroel jokowi...    no      0\n",
              "989   fikrii509 musim ujan bjir takut kena virus corona    no      0\n",
              "11    grosir masker spirulina depok sms wa 082258435...    no      0\n",
              "13    ramayanads ezash ramayana aja min depok graha ...    no      0\n",
              "1696  anies baswedan bentuk tim khusus posko tanggap...   yes      1"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# val\n",
        "df_dev['worth'] = df_dev['label'].apply(lambda x : 1 if x=='yes' else 0)\n",
        "df_dev.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZLHaTPWVGdr"
      },
      "source": [
        "## Cek Persebaran Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "E94PstJrsXg9",
        "outputId": "07b63607-8d1c-4b94-9300-5774dd76147a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'samples')"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x=df_train.worth.value_counts()\n",
        "sns.barplot(x.index,x)\n",
        "plt.gca().set_ylabel('samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TBkl9hRDBNtT"
      },
      "outputs": [],
      "source": [
        "sentences = df_train.text_a.values\n",
        "labels = df_train.worth.values\n",
        "\n",
        "sentences_test = df_test.text_a.values\n",
        "labels_test = df_test.worth.values\n",
        "\n",
        "sentences_val = df_dev.text_a.values\n",
        "labels_val = df_dev.worth.values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_N_mAW6fPmP"
      },
      "source": [
        "## **Load BERT Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMc4LncOHdtw",
        "outputId": "12923d03-acce-4c86-a5b9-734a11e41853"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading BERT Tokenizer\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print(\"Loading BERT Tokenizer\")\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased', do_lower_case=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NmgvKwtysJuq",
        "outputId": "a696d487-2fb6-4c75-83d5-b7e64190609a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bbf0b67c-0395-4637-a695-95683914f08e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text_a</th>\n",
              "      <th>label</th>\n",
              "      <th>worth</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5641</th>\n",
              "      <td>5641</td>\n",
              "      <td>cakndu27 cakasana cari endorse pemprov</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5747</th>\n",
              "      <td>5747</td>\n",
              "      <td>bansos polres cianjur program covid 19 polda j...</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6921</th>\n",
              "      <td>6921</td>\n",
              "      <td>fakta data umur 50 keatas rentan terjangkit vi...</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11081</th>\n",
              "      <td>11081</td>\n",
              "      <td>dapet kabar indonesia postif corona maafin kua...</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19472</th>\n",
              "      <td>19472</td>\n",
              "      <td>tu yg bilang indonesia kebal ame virus corona ...</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbf0b67c-0395-4637-a695-95683914f08e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bbf0b67c-0395-4637-a695-95683914f08e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bbf0b67c-0395-4637-a695-95683914f08e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Unnamed: 0                                             text_a label  \\\n",
              "5641         5641             cakndu27 cakasana cari endorse pemprov    no   \n",
              "5747         5747  bansos polres cianjur program covid 19 polda j...   yes   \n",
              "6921         6921  fakta data umur 50 keatas rentan terjangkit vi...   yes   \n",
              "11081       11081  dapet kabar indonesia postif corona maafin kua...   yes   \n",
              "19472       19472  tu yg bilang indonesia kebal ame virus corona ...    no   \n",
              "\n",
              "       worth  \n",
              "5641       0  \n",
              "5747       1  \n",
              "6921       1  \n",
              "11081      1  \n",
              "19472      0  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sprZdC1HlKrc"
      },
      "source": [
        "### Tokenisasi dan Mapping Token Sentence ke Index di Tokenizer Vocabulary milik BERT Base Multilingua Uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VfxuBuyIJxY",
        "outputId": "5c198b5a-39a4-4d2f-c01d-651710a7c6d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  betewe buka twitter cuman ngetweet liat home berita corona panik kepikiran ndamau buka2 home yg aware aja i ll stay at home nda rumah kalo nda penting2 banget\n",
            "Tokenized:  ['bete', '##we', 'bu', '##ka', 'twitter', 'cuma', '##n', 'ng', '##et', '##wee', '##t', 'lia', '##t', 'home', 'berita', 'corona', 'pani', '##k', 'kep', '##iki', '##ran', 'nda', '##mau', 'bu', '##ka', '##2', 'home', 'yg', 'aware', 'aja', 'i', 'll', 'stay', 'at', 'home', 'nda', 'rumah', 'kal', '##o', 'nda', 'penting', '##2', 'bang', '##et']\n",
            "Token IDS:  [78811, 12351, 10920, 10358, 23588, 94097, 10115, 10822, 10337, 67954, 10123, 60241, 10123, 11402, 62637, 20241, 49034, 10167, 65911, 23802, 12056, 24305, 84144, 10920, 10358, 10835, 11402, 95759, 58910, 57950, 151, 17361, 22560, 10160, 11402, 24305, 20297, 54376, 10132, 24305, 33815, 10835, 12221, 10337]\n"
          ]
        }
      ],
      "source": [
        "print(\"Original: \", sentences[0])\n",
        "\n",
        "print(\"Tokenized: \", tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "print(\"Token IDS: \", tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0p7umMVyQcOA"
      },
      "source": [
        "### Memberikan token [CLS] di awal Token IDS dan token [SEP] di akhir untuk sentences yang di tokenized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHPzXRJAITnv",
        "outputId": "edea54c5-97be-4316-9279-167394ea75e9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (704 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  betewe buka twitter cuman ngetweet liat home berita corona panik kepikiran ndamau buka2 home yg aware aja i ll stay at home nda rumah kalo nda penting2 banget\n",
            "Token IDs:  [101, 78811, 12351, 10920, 10358, 23588, 94097, 10115, 10822, 10337, 67954, 10123, 60241, 10123, 11402, 62637, 20241, 49034, 10167, 65911, 23802, 12056, 24305, 84144, 10920, 10358, 10835, 11402, 95759, 58910, 57950, 151, 17361, 22560, 10160, 11402, 24305, 20297, 54376, 10132, 24305, 33815, 10835, 12221, 10337, 102]\n"
          ]
        }
      ],
      "source": [
        "# for train data\n",
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "  encoded_sent = tokenizer.encode(\n",
        "      sent,\n",
        "      add_special_tokens = True\n",
        "  )\n",
        "  input_ids.append(encoded_sent)\n",
        "\n",
        "print(\"Original: \", sentences[0])\n",
        "print(\"Token IDs: \", input_ids[0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhCLX6SjbT9g",
        "outputId": "b62a0255-751d-419f-d316-cb314fe02a0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  jek dajal ga depok bang\n",
            "Token IDs:  [101, 10149, 10167, 10141, 24842, 11747, 10102, 41938, 12221, 102]\n"
          ]
        }
      ],
      "source": [
        "# for test data\n",
        "input_ids_test = []\n",
        "\n",
        "for sent in sentences_test:\n",
        "  encoded_sent = tokenizer.encode(\n",
        "      sent,\n",
        "      add_special_tokens = True\n",
        "  )\n",
        "  input_ids_test.append(encoded_sent)\n",
        "\n",
        "print(\"Original: \", sentences_test[0])\n",
        "print(\"Token IDs: \", input_ids_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syQY0KYRgESj",
        "outputId": "2bcc7d1a-cba4-4f65-c123-4bcc7126a0dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  jek dajal ga depok bang\n",
            "Token IDs:  [101, 10149, 10167, 10141, 24842, 11747, 10102, 41938, 12221, 102]\n"
          ]
        }
      ],
      "source": [
        "# for val\n",
        "input_ids_val = []\n",
        "\n",
        "for sent in sentences_val:\n",
        "  encoded_sent = tokenizer.encode(\n",
        "      sent,\n",
        "      add_special_tokens = True\n",
        "  )\n",
        "  input_ids_val.append(encoded_sent)\n",
        "\n",
        "print(\"Original: \", sentences_val[0])\n",
        "print(\"Token IDs: \", input_ids_val[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5rgsfQHmSTw",
        "outputId": "2274afad-2906-434b-c8f5-0302d025575d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  2639\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "print(\"Max sentence length: \", max([len(sen) for sen in input_ids]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C6rSI5bbxT-",
        "outputId": "fafa64bd-77f3-40eb-ac36-009931daa7c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  640\n"
          ]
        }
      ],
      "source": [
        "# test data\n",
        "print(\"Max sentence length: \", max([len(sen) for sen in input_ids_test]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMwXeRHhgz8i",
        "outputId": "793b39f5-0b76-42ff-86a4-ac3b014b41a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  640\n"
          ]
        }
      ],
      "source": [
        "# dev/val\n",
        "print(\"Max sentence length: \", max([len(sen) for sen in input_ids_val]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no-qmKCxROOz"
      },
      "source": [
        "### Memberikan Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ER5yGm8meLg",
        "outputId": "addce4ab-1675-457c-b9c8-fef025082a21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding/truncating all sentences to 64 values\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "print(\"Padding/truncating all sentences to %d values\" % MAX_LEN)\n",
        "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype='long', value=0, truncating='post', padding='post')\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcutWSepcVYl",
        "outputId": "fd5c9017-2288-4eb2-c5b4-cc8a258e410e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding/truncating all sentences to 64 values\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# test data\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "print(\"Padding/truncating all sentences to %d values\" % MAX_LEN)\n",
        "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype='long', value=0, truncating='post', padding='post')\n",
        "\n",
        "print(\"Done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6Y5PJfEhAFx",
        "outputId": "1a7e6d52-13df-4daa-b0f7-ca81b637a02f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Padding/truncating all sentences to 64 values\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "Done\n"
          ]
        }
      ],
      "source": [
        "# val\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_LEN = 64\n",
        "\n",
        "print(\"Padding/truncating all sentences to %d values\" % MAX_LEN)\n",
        "print('Padding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids_val = pad_sequences(input_ids_val, maxlen=MAX_LEN, dtype='long', value=0, truncating='post', padding='post')\n",
        "\n",
        "print(\"Done\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5a-z495RVJa"
      },
      "source": [
        "### Attention Mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xgbpf1fWoCYv"
      },
      "outputs": [],
      "source": [
        "attention_mask_train = []\n",
        "\n",
        "for sent in input_ids:\n",
        "  att_mask_train = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  attention_mask_train.append(att_mask_train)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LWMoz6I4c7jF"
      },
      "outputs": [],
      "source": [
        "attention_mask_test = []\n",
        "\n",
        "for sent in input_ids_test:\n",
        "  att_mask_test = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  attention_mask_test.append(att_mask_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qZ2KRKPJhq8r"
      },
      "outputs": [],
      "source": [
        "attention_mask_val = []\n",
        "\n",
        "for sent in input_ids_test:\n",
        "  att_mask_val = [int(token_id > 0) for token_id in sent]\n",
        "\n",
        "  attention_mask_val.append(att_mask_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQybI-XdfpBs"
      },
      "source": [
        "## **Persiapkan data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcbrNxAOiKzg",
        "outputId": "6d80166a-8c1e-4eb7-89a8-c4e5eaf26d06"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(21601, 64)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "# train & test\n",
        "train_input = input_ids.copy()\n",
        "train_labels = labels.copy()\n",
        "test_input = input_ids_test.copy()\n",
        "test_labels = labels_test.copy()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# mask train & test\n",
        "train_mask = attention_mask_train.copy()\n",
        "test_mask =attention_mask_test.copy()\n",
        "\n",
        "\n",
        "\n",
        "# val\n",
        "validation_input = input_ids_val.copy()\n",
        "validation_labels = labels_val.copy()\n",
        "\n",
        "\n",
        "\n",
        "# mask val\n",
        "validation_mask = attention_mask_val.copy()\n",
        "\n",
        "# train_input[0]\n",
        "input_ids.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSsCBgJKs5S3",
        "outputId": "afc147c1-9714-41d3-c906-56ef36563e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "== Train ==\n",
            "Input:  (21601, 64)\n",
            "Label:  (21601,)\n",
            "Mask:  (21601, 64)\n",
            "\n",
            "== Validation ==\n",
            "Input:  (2800, 64)\n",
            "Label:  (2800,)\n",
            "Mask:  (2800, 64)\n",
            "\n",
            "== Test ==\n",
            "Input:  (2800, 64)\n",
            "Label:  (2800,)\n",
            "Mask:  (2800, 64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(\"== Train ==\")\n",
        "print(\"Input: \", train_input.shape)\n",
        "print(\"Label: \", train_labels.shape)\n",
        "print(\"Mask: \", np.array(train_mask).shape)\n",
        "\n",
        "print(\"\\n== Validation ==\")\n",
        "print(\"Input: \", validation_input.shape)\n",
        "print(\"Label: \", validation_labels.shape)\n",
        "print(\"Mask: \", np.array(validation_mask).shape)\n",
        "\n",
        "print(\"\\n== Test ==\")\n",
        "print(\"Input: \", test_input.shape)\n",
        "print(\"Label: \", test_labels.shape)\n",
        "print(\"Mask: \", np.array(test_mask).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "uftrQNKItAQf"
      },
      "outputs": [],
      "source": [
        "train_input = torch.tensor(train_input)\n",
        "train_labels = torch.tensor(train_labels)\n",
        "train_mask = torch.tensor(train_mask)\n",
        "\n",
        "validation_input = torch.tensor(validation_input)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "validation_mask = torch.tensor(validation_mask)\n",
        "\n",
        "test_input = torch.tensor(test_input)\n",
        "test_labels = torch.tensor(test_labels)\n",
        "test_mask = torch.tensor(test_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "1CmnMnE2q12L"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "train_data = TensorDataset(train_input, train_mask, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_input, validation_mask, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_input, test_mask, test_labels)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POIzdHuXf0U5"
      },
      "source": [
        "## **Persiapkan model pre-trained BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4_N0-MosMQM",
        "outputId": "50306d32-c0e6-452b-ad12-f982c1a7f04f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-multilingual-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(105879, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False\n",
        ")\n",
        "\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hWDIP0nNwHy",
        "outputId": "1496a153-6745-421c-b2aa-c04f5d0bc0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "==== Embedding Layer ====\n",
            "bert.embeddings.word_embeddings.weight                       (105879, 768)\n",
            "bert.embeddings.position_embeddings.weight                     (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                     (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                                   (768,)\n",
            "bert.embeddings.LayerNorm.bias                                     (768,)\n",
            "==== First Transformers ====\n",
            "bert.encoder.layer.0.attention.self.query.weight               (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                     (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                       (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight               (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                     (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias                   (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                      (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                             (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
            "==== Output Layer ====\n",
            "bert.pooler.dense.weight                                       (768, 768)\n",
            "bert.pooler.dense.bias                                             (768,)\n",
            "classifier.weight                                                (2, 768)\n",
            "classifier.bias                                                      (2,)\n"
          ]
        }
      ],
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print(\"The BERT model has {:} different named parameters.\".format(len(params)))\n",
        "\n",
        "print(\"==== Embedding Layer ====\")\n",
        "for p in params[0:5]:\n",
        "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"==== First Transformers ====\")\n",
        "for p in params[5:21]:\n",
        "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print(\"==== Output Layer ====\")\n",
        "for p in params[-4:]:\n",
        "  print(\"{:<60} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3bDZ9ksgsF"
      },
      "source": [
        "### Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tBz9rRPOx_Q",
        "outputId": "4ebd0641-72c5-4267-ae56-f412e2401d53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr = 2e-5,\n",
        "    eps = 1e-8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "bgi-3UW3PaRK"
      },
      "outputs": [],
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                             num_warmup_steps = 0,\n",
        "                                             num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "oroRGhupPkOz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "53eJ-lpdTEG1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "  elapsed_rounded = int(round(elapsed))\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiJzxtBAgHh3"
      },
      "source": [
        "## **Training BERT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epokdnpjTVaR",
        "outputId": "3c302ee6-b918-4e06-f157-03f885e1171a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======= Epoch 1 / 5 =======\n",
            "Training...\n",
            "Batch    40 of 2,701.     Elapsed: 0:00:06\n",
            "Batch    80 of 2,701.     Elapsed: 0:00:12\n",
            "Batch   120 of 2,701.     Elapsed: 0:00:17\n",
            "Batch   160 of 2,701.     Elapsed: 0:00:23\n",
            "Batch   200 of 2,701.     Elapsed: 0:00:28\n",
            "Batch   240 of 2,701.     Elapsed: 0:00:34\n",
            "Batch   280 of 2,701.     Elapsed: 0:00:39\n",
            "Batch   320 of 2,701.     Elapsed: 0:00:45\n",
            "Batch   360 of 2,701.     Elapsed: 0:00:51\n",
            "Batch   400 of 2,701.     Elapsed: 0:00:56\n",
            "Batch   440 of 2,701.     Elapsed: 0:01:02\n",
            "Batch   480 of 2,701.     Elapsed: 0:01:07\n",
            "Batch   520 of 2,701.     Elapsed: 0:01:13\n",
            "Batch   560 of 2,701.     Elapsed: 0:01:19\n",
            "Batch   600 of 2,701.     Elapsed: 0:01:24\n",
            "Batch   640 of 2,701.     Elapsed: 0:01:30\n",
            "Batch   680 of 2,701.     Elapsed: 0:01:36\n",
            "Batch   720 of 2,701.     Elapsed: 0:01:41\n",
            "Batch   760 of 2,701.     Elapsed: 0:01:47\n",
            "Batch   800 of 2,701.     Elapsed: 0:01:53\n",
            "Batch   840 of 2,701.     Elapsed: 0:01:58\n",
            "Batch   880 of 2,701.     Elapsed: 0:02:04\n",
            "Batch   920 of 2,701.     Elapsed: 0:02:10\n",
            "Batch   960 of 2,701.     Elapsed: 0:02:16\n",
            "Batch 1,000 of 2,701.     Elapsed: 0:02:21\n",
            "Batch 1,040 of 2,701.     Elapsed: 0:02:27\n",
            "Batch 1,080 of 2,701.     Elapsed: 0:02:33\n",
            "Batch 1,120 of 2,701.     Elapsed: 0:02:38\n",
            "Batch 1,160 of 2,701.     Elapsed: 0:02:44\n",
            "Batch 1,200 of 2,701.     Elapsed: 0:02:50\n",
            "Batch 1,240 of 2,701.     Elapsed: 0:02:55\n",
            "Batch 1,280 of 2,701.     Elapsed: 0:03:01\n",
            "Batch 1,320 of 2,701.     Elapsed: 0:03:07\n",
            "Batch 1,360 of 2,701.     Elapsed: 0:03:13\n",
            "Batch 1,400 of 2,701.     Elapsed: 0:03:18\n",
            "Batch 1,440 of 2,701.     Elapsed: 0:03:24\n",
            "Batch 1,480 of 2,701.     Elapsed: 0:03:30\n",
            "Batch 1,520 of 2,701.     Elapsed: 0:03:35\n",
            "Batch 1,560 of 2,701.     Elapsed: 0:03:41\n",
            "Batch 1,600 of 2,701.     Elapsed: 0:03:47\n",
            "Batch 1,640 of 2,701.     Elapsed: 0:03:52\n",
            "Batch 1,680 of 2,701.     Elapsed: 0:03:58\n",
            "Batch 1,720 of 2,701.     Elapsed: 0:04:04\n",
            "Batch 1,760 of 2,701.     Elapsed: 0:04:09\n",
            "Batch 1,800 of 2,701.     Elapsed: 0:04:15\n",
            "Batch 1,840 of 2,701.     Elapsed: 0:04:21\n",
            "Batch 1,880 of 2,701.     Elapsed: 0:04:28\n",
            "Batch 1,920 of 2,701.     Elapsed: 0:04:33\n",
            "Batch 1,960 of 2,701.     Elapsed: 0:04:39\n",
            "Batch 2,000 of 2,701.     Elapsed: 0:04:45\n",
            "Batch 2,040 of 2,701.     Elapsed: 0:04:51\n",
            "Batch 2,080 of 2,701.     Elapsed: 0:04:56\n",
            "Batch 2,120 of 2,701.     Elapsed: 0:05:02\n",
            "Batch 2,160 of 2,701.     Elapsed: 0:05:08\n",
            "Batch 2,200 of 2,701.     Elapsed: 0:05:13\n",
            "Batch 2,240 of 2,701.     Elapsed: 0:05:19\n",
            "Batch 2,280 of 2,701.     Elapsed: 0:05:25\n",
            "Batch 2,320 of 2,701.     Elapsed: 0:05:31\n",
            "Batch 2,360 of 2,701.     Elapsed: 0:05:36\n",
            "Batch 2,400 of 2,701.     Elapsed: 0:05:43\n",
            "Batch 2,440 of 2,701.     Elapsed: 0:05:48\n",
            "Batch 2,480 of 2,701.     Elapsed: 0:05:54\n",
            "Batch 2,520 of 2,701.     Elapsed: 0:06:00\n",
            "Batch 2,560 of 2,701.     Elapsed: 0:06:05\n",
            "Batch 2,600 of 2,701.     Elapsed: 0:06:11\n",
            "Batch 2,640 of 2,701.     Elapsed: 0:06:17\n",
            "Batch 2,680 of 2,701.     Elapsed: 0:06:22\n",
            "   Average training loss: 0.39\n",
            "   Training epoch took: 0:06:25\n",
            "Running Validation...\n",
            "   Accuracy: 0.85\n",
            "   Validation took: 0:00:10\n",
            "======= Epoch 2 / 5 =======\n",
            "Training...\n",
            "Batch    40 of 2,701.     Elapsed: 0:00:06\n",
            "Batch    80 of 2,701.     Elapsed: 0:00:11\n",
            "Batch   120 of 2,701.     Elapsed: 0:00:17\n",
            "Batch   160 of 2,701.     Elapsed: 0:00:23\n",
            "Batch   200 of 2,701.     Elapsed: 0:00:28\n",
            "Batch   240 of 2,701.     Elapsed: 0:00:34\n",
            "Batch   280 of 2,701.     Elapsed: 0:00:40\n",
            "Batch   320 of 2,701.     Elapsed: 0:00:46\n",
            "Batch   360 of 2,701.     Elapsed: 0:00:51\n",
            "Batch   400 of 2,701.     Elapsed: 0:00:57\n",
            "Batch   440 of 2,701.     Elapsed: 0:01:03\n",
            "Batch   480 of 2,701.     Elapsed: 0:01:08\n",
            "Batch   520 of 2,701.     Elapsed: 0:01:14\n",
            "Batch   560 of 2,701.     Elapsed: 0:01:20\n",
            "Batch   600 of 2,701.     Elapsed: 0:01:25\n",
            "Batch   640 of 2,701.     Elapsed: 0:01:31\n",
            "Batch   680 of 2,701.     Elapsed: 0:01:37\n",
            "Batch   720 of 2,701.     Elapsed: 0:01:43\n",
            "Batch   760 of 2,701.     Elapsed: 0:01:48\n",
            "Batch   800 of 2,701.     Elapsed: 0:01:54\n",
            "Batch   840 of 2,701.     Elapsed: 0:02:00\n",
            "Batch   880 of 2,701.     Elapsed: 0:02:05\n",
            "Batch   920 of 2,701.     Elapsed: 0:02:11\n",
            "Batch   960 of 2,701.     Elapsed: 0:02:17\n",
            "Batch 1,000 of 2,701.     Elapsed: 0:02:22\n",
            "Batch 1,040 of 2,701.     Elapsed: 0:02:28\n",
            "Batch 1,080 of 2,701.     Elapsed: 0:02:34\n",
            "Batch 1,120 of 2,701.     Elapsed: 0:02:39\n",
            "Batch 1,160 of 2,701.     Elapsed: 0:02:45\n",
            "Batch 1,200 of 2,701.     Elapsed: 0:02:51\n",
            "Batch 1,240 of 2,701.     Elapsed: 0:02:57\n",
            "Batch 1,280 of 2,701.     Elapsed: 0:03:02\n",
            "Batch 1,320 of 2,701.     Elapsed: 0:03:08\n",
            "Batch 1,360 of 2,701.     Elapsed: 0:03:14\n",
            "Batch 1,400 of 2,701.     Elapsed: 0:03:19\n",
            "Batch 1,440 of 2,701.     Elapsed: 0:03:25\n",
            "Batch 1,480 of 2,701.     Elapsed: 0:03:31\n",
            "Batch 1,520 of 2,701.     Elapsed: 0:03:36\n",
            "Batch 1,560 of 2,701.     Elapsed: 0:03:42\n",
            "Batch 1,600 of 2,701.     Elapsed: 0:03:48\n",
            "Batch 1,640 of 2,701.     Elapsed: 0:03:53\n",
            "Batch 1,680 of 2,701.     Elapsed: 0:03:59\n",
            "Batch 1,720 of 2,701.     Elapsed: 0:04:05\n",
            "Batch 1,760 of 2,701.     Elapsed: 0:04:11\n",
            "Batch 1,800 of 2,701.     Elapsed: 0:04:16\n",
            "Batch 1,840 of 2,701.     Elapsed: 0:04:22\n",
            "Batch 1,880 of 2,701.     Elapsed: 0:04:28\n",
            "Batch 1,920 of 2,701.     Elapsed: 0:04:33\n",
            "Batch 1,960 of 2,701.     Elapsed: 0:04:39\n",
            "Batch 2,000 of 2,701.     Elapsed: 0:04:45\n",
            "Batch 2,040 of 2,701.     Elapsed: 0:04:50\n",
            "Batch 2,080 of 2,701.     Elapsed: 0:04:56\n",
            "Batch 2,120 of 2,701.     Elapsed: 0:05:02\n",
            "Batch 2,160 of 2,701.     Elapsed: 0:05:07\n",
            "Batch 2,200 of 2,701.     Elapsed: 0:05:13\n",
            "Batch 2,240 of 2,701.     Elapsed: 0:05:19\n",
            "Batch 2,280 of 2,701.     Elapsed: 0:05:25\n",
            "Batch 2,320 of 2,701.     Elapsed: 0:05:30\n",
            "Batch 2,360 of 2,701.     Elapsed: 0:05:36\n",
            "Batch 2,400 of 2,701.     Elapsed: 0:05:42\n",
            "Batch 2,440 of 2,701.     Elapsed: 0:05:47\n",
            "Batch 2,480 of 2,701.     Elapsed: 0:05:53\n",
            "Batch 2,520 of 2,701.     Elapsed: 0:05:59\n",
            "Batch 2,560 of 2,701.     Elapsed: 0:06:04\n",
            "Batch 2,600 of 2,701.     Elapsed: 0:06:10\n",
            "Batch 2,640 of 2,701.     Elapsed: 0:06:16\n",
            "Batch 2,680 of 2,701.     Elapsed: 0:06:22\n",
            "   Average training loss: 0.30\n",
            "   Training epoch took: 0:06:24\n",
            "Running Validation...\n",
            "   Accuracy: 0.83\n",
            "   Validation took: 0:00:10\n",
            "======= Epoch 3 / 5 =======\n",
            "Training...\n",
            "Batch    40 of 2,701.     Elapsed: 0:00:06\n",
            "Batch    80 of 2,701.     Elapsed: 0:00:11\n",
            "Batch   120 of 2,701.     Elapsed: 0:00:17\n",
            "Batch   160 of 2,701.     Elapsed: 0:00:23\n",
            "Batch   200 of 2,701.     Elapsed: 0:00:29\n",
            "Batch   240 of 2,701.     Elapsed: 0:00:34\n",
            "Batch   280 of 2,701.     Elapsed: 0:00:40\n",
            "Batch   320 of 2,701.     Elapsed: 0:00:46\n",
            "Batch   360 of 2,701.     Elapsed: 0:00:51\n",
            "Batch   400 of 2,701.     Elapsed: 0:00:57\n",
            "Batch   440 of 2,701.     Elapsed: 0:01:03\n",
            "Batch   480 of 2,701.     Elapsed: 0:01:08\n",
            "Batch   520 of 2,701.     Elapsed: 0:01:14\n",
            "Batch   560 of 2,701.     Elapsed: 0:01:20\n",
            "Batch   600 of 2,701.     Elapsed: 0:01:26\n",
            "Batch   640 of 2,701.     Elapsed: 0:01:31\n",
            "Batch   680 of 2,701.     Elapsed: 0:01:37\n",
            "Batch   720 of 2,701.     Elapsed: 0:01:43\n",
            "Batch   760 of 2,701.     Elapsed: 0:01:48\n",
            "Batch   800 of 2,701.     Elapsed: 0:01:54\n",
            "Batch   840 of 2,701.     Elapsed: 0:02:00\n",
            "Batch   880 of 2,701.     Elapsed: 0:02:05\n",
            "Batch   920 of 2,701.     Elapsed: 0:02:11\n",
            "Batch   960 of 2,701.     Elapsed: 0:02:17\n",
            "Batch 1,000 of 2,701.     Elapsed: 0:02:22\n",
            "Batch 1,040 of 2,701.     Elapsed: 0:02:28\n",
            "Batch 1,080 of 2,701.     Elapsed: 0:02:34\n",
            "Batch 1,120 of 2,701.     Elapsed: 0:02:40\n",
            "Batch 1,160 of 2,701.     Elapsed: 0:02:45\n",
            "Batch 1,200 of 2,701.     Elapsed: 0:02:51\n",
            "Batch 1,240 of 2,701.     Elapsed: 0:02:57\n",
            "Batch 1,280 of 2,701.     Elapsed: 0:03:02\n",
            "Batch 1,320 of 2,701.     Elapsed: 0:03:08\n",
            "Batch 1,360 of 2,701.     Elapsed: 0:03:14\n",
            "Batch 1,400 of 2,701.     Elapsed: 0:03:19\n",
            "Batch 1,440 of 2,701.     Elapsed: 0:03:25\n",
            "Batch 1,480 of 2,701.     Elapsed: 0:03:31\n",
            "Batch 1,520 of 2,701.     Elapsed: 0:03:37\n",
            "Batch 1,560 of 2,701.     Elapsed: 0:03:42\n",
            "Batch 1,600 of 2,701.     Elapsed: 0:03:48\n",
            "Batch 1,640 of 2,701.     Elapsed: 0:03:54\n",
            "Batch 1,680 of 2,701.     Elapsed: 0:03:59\n",
            "Batch 1,720 of 2,701.     Elapsed: 0:04:05\n",
            "Batch 1,760 of 2,701.     Elapsed: 0:04:11\n",
            "Batch 1,800 of 2,701.     Elapsed: 0:04:16\n",
            "Batch 1,840 of 2,701.     Elapsed: 0:04:22\n",
            "Batch 1,880 of 2,701.     Elapsed: 0:04:28\n",
            "Batch 1,920 of 2,701.     Elapsed: 0:04:33\n",
            "Batch 1,960 of 2,701.     Elapsed: 0:04:39\n",
            "Batch 2,000 of 2,701.     Elapsed: 0:04:45\n",
            "Batch 2,040 of 2,701.     Elapsed: 0:04:51\n",
            "Batch 2,080 of 2,701.     Elapsed: 0:04:56\n",
            "Batch 2,120 of 2,701.     Elapsed: 0:05:02\n",
            "Batch 2,160 of 2,701.     Elapsed: 0:05:08\n",
            "Batch 2,200 of 2,701.     Elapsed: 0:05:13\n",
            "Batch 2,240 of 2,701.     Elapsed: 0:05:19\n",
            "Batch 2,280 of 2,701.     Elapsed: 0:05:25\n",
            "Batch 2,320 of 2,701.     Elapsed: 0:05:30\n",
            "Batch 2,360 of 2,701.     Elapsed: 0:05:36\n",
            "Batch 2,400 of 2,701.     Elapsed: 0:05:42\n",
            "Batch 2,440 of 2,701.     Elapsed: 0:05:47\n",
            "Batch 2,480 of 2,701.     Elapsed: 0:05:53\n",
            "Batch 2,520 of 2,701.     Elapsed: 0:05:59\n",
            "Batch 2,560 of 2,701.     Elapsed: 0:06:05\n",
            "Batch 2,600 of 2,701.     Elapsed: 0:06:10\n",
            "Batch 2,640 of 2,701.     Elapsed: 0:06:16\n",
            "Batch 2,680 of 2,701.     Elapsed: 0:06:22\n",
            "   Average training loss: 0.23\n",
            "   Training epoch took: 0:06:25\n",
            "Running Validation...\n",
            "   Accuracy: 0.86\n",
            "   Validation took: 0:00:10\n",
            "======= Epoch 4 / 5 =======\n",
            "Training...\n",
            "Batch    40 of 2,701.     Elapsed: 0:00:06\n",
            "Batch    80 of 2,701.     Elapsed: 0:00:11\n",
            "Batch   120 of 2,701.     Elapsed: 0:00:17\n",
            "Batch   160 of 2,701.     Elapsed: 0:00:23\n",
            "Batch   200 of 2,701.     Elapsed: 0:00:28\n",
            "Batch   240 of 2,701.     Elapsed: 0:00:34\n",
            "Batch   280 of 2,701.     Elapsed: 0:00:40\n",
            "Batch   320 of 2,701.     Elapsed: 0:00:46\n",
            "Batch   360 of 2,701.     Elapsed: 0:00:51\n",
            "Batch   400 of 2,701.     Elapsed: 0:00:57\n",
            "Batch   440 of 2,701.     Elapsed: 0:01:03\n",
            "Batch   480 of 2,701.     Elapsed: 0:01:08\n",
            "Batch   520 of 2,701.     Elapsed: 0:01:14\n",
            "Batch   560 of 2,701.     Elapsed: 0:01:20\n",
            "Batch   600 of 2,701.     Elapsed: 0:01:25\n",
            "Batch   640 of 2,701.     Elapsed: 0:01:31\n",
            "Batch   680 of 2,701.     Elapsed: 0:01:37\n",
            "Batch   720 of 2,701.     Elapsed: 0:01:43\n",
            "Batch   760 of 2,701.     Elapsed: 0:01:48\n",
            "Batch   800 of 2,701.     Elapsed: 0:01:54\n",
            "Batch   840 of 2,701.     Elapsed: 0:02:00\n",
            "Batch   880 of 2,701.     Elapsed: 0:02:05\n",
            "Batch   920 of 2,701.     Elapsed: 0:02:11\n",
            "Batch   960 of 2,701.     Elapsed: 0:02:17\n",
            "Batch 1,000 of 2,701.     Elapsed: 0:02:22\n",
            "Batch 1,040 of 2,701.     Elapsed: 0:02:28\n",
            "Batch 1,080 of 2,701.     Elapsed: 0:02:34\n",
            "Batch 1,120 of 2,701.     Elapsed: 0:02:39\n",
            "Batch 1,160 of 2,701.     Elapsed: 0:02:45\n",
            "Batch 1,200 of 2,701.     Elapsed: 0:02:51\n",
            "Batch 1,240 of 2,701.     Elapsed: 0:02:57\n",
            "Batch 1,280 of 2,701.     Elapsed: 0:03:02\n",
            "Batch 1,320 of 2,701.     Elapsed: 0:03:08\n",
            "Batch 1,360 of 2,701.     Elapsed: 0:03:14\n",
            "Batch 1,400 of 2,701.     Elapsed: 0:03:19\n",
            "Batch 1,440 of 2,701.     Elapsed: 0:03:25\n",
            "Batch 1,480 of 2,701.     Elapsed: 0:03:31\n",
            "Batch 1,520 of 2,701.     Elapsed: 0:03:36\n",
            "Batch 1,560 of 2,701.     Elapsed: 0:03:42\n",
            "Batch 1,600 of 2,701.     Elapsed: 0:03:48\n",
            "Batch 1,640 of 2,701.     Elapsed: 0:03:54\n",
            "Batch 1,680 of 2,701.     Elapsed: 0:03:59\n",
            "Batch 1,720 of 2,701.     Elapsed: 0:04:05\n",
            "Batch 1,760 of 2,701.     Elapsed: 0:04:11\n",
            "Batch 1,800 of 2,701.     Elapsed: 0:04:17\n",
            "Batch 1,840 of 2,701.     Elapsed: 0:04:22\n",
            "Batch 1,880 of 2,701.     Elapsed: 0:04:28\n",
            "Batch 1,920 of 2,701.     Elapsed: 0:04:34\n",
            "Batch 1,960 of 2,701.     Elapsed: 0:04:39\n",
            "Batch 2,000 of 2,701.     Elapsed: 0:04:45\n",
            "Batch 2,040 of 2,701.     Elapsed: 0:04:51\n",
            "Batch 2,080 of 2,701.     Elapsed: 0:04:57\n",
            "Batch 2,120 of 2,701.     Elapsed: 0:05:02\n",
            "Batch 2,160 of 2,701.     Elapsed: 0:05:08\n",
            "Batch 2,200 of 2,701.     Elapsed: 0:05:14\n",
            "Batch 2,240 of 2,701.     Elapsed: 0:05:19\n",
            "Batch 2,280 of 2,701.     Elapsed: 0:05:25\n",
            "Batch 2,320 of 2,701.     Elapsed: 0:05:31\n",
            "Batch 2,360 of 2,701.     Elapsed: 0:05:36\n",
            "Batch 2,400 of 2,701.     Elapsed: 0:05:42\n",
            "Batch 2,440 of 2,701.     Elapsed: 0:05:48\n",
            "Batch 2,480 of 2,701.     Elapsed: 0:05:53\n",
            "Batch 2,520 of 2,701.     Elapsed: 0:05:59\n",
            "Batch 2,560 of 2,701.     Elapsed: 0:06:05\n",
            "Batch 2,600 of 2,701.     Elapsed: 0:06:11\n",
            "Batch 2,640 of 2,701.     Elapsed: 0:06:16\n",
            "Batch 2,680 of 2,701.     Elapsed: 0:06:22\n",
            "   Average training loss: 0.17\n",
            "   Training epoch took: 0:06:25\n",
            "Running Validation...\n",
            "   Accuracy: 0.86\n",
            "   Validation took: 0:00:10\n",
            "======= Epoch 5 / 5 =======\n",
            "Training...\n",
            "Batch    40 of 2,701.     Elapsed: 0:00:06\n",
            "Batch    80 of 2,701.     Elapsed: 0:00:11\n",
            "Batch   120 of 2,701.     Elapsed: 0:00:17\n",
            "Batch   160 of 2,701.     Elapsed: 0:00:23\n",
            "Batch   200 of 2,701.     Elapsed: 0:00:28\n",
            "Batch   240 of 2,701.     Elapsed: 0:00:34\n",
            "Batch   280 of 2,701.     Elapsed: 0:00:40\n",
            "Batch   320 of 2,701.     Elapsed: 0:00:46\n",
            "Batch   360 of 2,701.     Elapsed: 0:00:51\n",
            "Batch   400 of 2,701.     Elapsed: 0:00:57\n",
            "Batch   440 of 2,701.     Elapsed: 0:01:03\n",
            "Batch   480 of 2,701.     Elapsed: 0:01:08\n",
            "Batch   520 of 2,701.     Elapsed: 0:01:14\n",
            "Batch   560 of 2,701.     Elapsed: 0:01:20\n",
            "Batch   600 of 2,701.     Elapsed: 0:01:25\n",
            "Batch   640 of 2,701.     Elapsed: 0:01:31\n",
            "Batch   680 of 2,701.     Elapsed: 0:01:37\n",
            "Batch   720 of 2,701.     Elapsed: 0:01:42\n",
            "Batch   760 of 2,701.     Elapsed: 0:01:48\n",
            "Batch   800 of 2,701.     Elapsed: 0:01:54\n",
            "Batch   840 of 2,701.     Elapsed: 0:02:00\n",
            "Batch   880 of 2,701.     Elapsed: 0:02:05\n",
            "Batch   920 of 2,701.     Elapsed: 0:02:11\n",
            "Batch   960 of 2,701.     Elapsed: 0:02:17\n",
            "Batch 1,000 of 2,701.     Elapsed: 0:02:22\n",
            "Batch 1,040 of 2,701.     Elapsed: 0:02:28\n",
            "Batch 1,080 of 2,701.     Elapsed: 0:02:34\n",
            "Batch 1,120 of 2,701.     Elapsed: 0:02:39\n",
            "Batch 1,160 of 2,701.     Elapsed: 0:02:45\n",
            "Batch 1,200 of 2,701.     Elapsed: 0:02:51\n",
            "Batch 1,240 of 2,701.     Elapsed: 0:02:57\n",
            "Batch 1,280 of 2,701.     Elapsed: 0:03:02\n",
            "Batch 1,320 of 2,701.     Elapsed: 0:03:08\n",
            "Batch 1,360 of 2,701.     Elapsed: 0:03:14\n",
            "Batch 1,400 of 2,701.     Elapsed: 0:03:19\n",
            "Batch 1,440 of 2,701.     Elapsed: 0:03:25\n",
            "Batch 1,480 of 2,701.     Elapsed: 0:03:31\n",
            "Batch 1,520 of 2,701.     Elapsed: 0:03:36\n",
            "Batch 1,560 of 2,701.     Elapsed: 0:03:42\n",
            "Batch 1,600 of 2,701.     Elapsed: 0:03:48\n",
            "Batch 1,640 of 2,701.     Elapsed: 0:03:53\n",
            "Batch 1,680 of 2,701.     Elapsed: 0:03:59\n",
            "Batch 1,720 of 2,701.     Elapsed: 0:04:05\n",
            "Batch 1,760 of 2,701.     Elapsed: 0:04:11\n",
            "Batch 1,800 of 2,701.     Elapsed: 0:04:16\n",
            "Batch 1,840 of 2,701.     Elapsed: 0:04:22\n",
            "Batch 1,880 of 2,701.     Elapsed: 0:04:28\n",
            "Batch 1,920 of 2,701.     Elapsed: 0:04:33\n",
            "Batch 1,960 of 2,701.     Elapsed: 0:04:39\n",
            "Batch 2,000 of 2,701.     Elapsed: 0:04:45\n",
            "Batch 2,040 of 2,701.     Elapsed: 0:04:50\n",
            "Batch 2,080 of 2,701.     Elapsed: 0:04:56\n",
            "Batch 2,120 of 2,701.     Elapsed: 0:05:02\n",
            "Batch 2,160 of 2,701.     Elapsed: 0:05:08\n",
            "Batch 2,200 of 2,701.     Elapsed: 0:05:13\n",
            "Batch 2,240 of 2,701.     Elapsed: 0:05:19\n",
            "Batch 2,280 of 2,701.     Elapsed: 0:05:25\n",
            "Batch 2,320 of 2,701.     Elapsed: 0:05:30\n",
            "Batch 2,360 of 2,701.     Elapsed: 0:05:36\n",
            "Batch 2,400 of 2,701.     Elapsed: 0:05:42\n",
            "Batch 2,440 of 2,701.     Elapsed: 0:05:47\n",
            "Batch 2,480 of 2,701.     Elapsed: 0:05:53\n",
            "Batch 2,520 of 2,701.     Elapsed: 0:05:59\n",
            "Batch 2,560 of 2,701.     Elapsed: 0:06:04\n",
            "Batch 2,600 of 2,701.     Elapsed: 0:06:10\n",
            "Batch 2,640 of 2,701.     Elapsed: 0:06:16\n",
            "Batch 2,680 of 2,701.     Elapsed: 0:06:22\n",
            "   Average training loss: 0.12\n",
            "   Training epoch took: 0:06:25\n",
            "Running Validation...\n",
            "   Accuracy: 0.85\n",
            "   Validation took: 0:00:10\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "  # ===================================\n",
        "  #              Training\n",
        "  # ===================================\n",
        "\n",
        "  print(\"======= Epoch {:} / {:} =======\".format(epoch_i+1, epochs))\n",
        "  print(\"Training...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  total_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  # For each batch of training data\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "\n",
        "      print(\"Batch {:>5,} of {:>5,}.     Elapsed: {:}\".format(step, len(train_dataloader), elapsed))\n",
        "    \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "    \n",
        "    loss = outputs[0]\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "  avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "  loss_values.append(avg_train_loss)\n",
        "\n",
        "  print(\"   Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "  print(\"   Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "  # ===================================\n",
        "  #             Validation\n",
        "  # ===================================\n",
        "\n",
        "  print(\"Running Validation...\")\n",
        "\n",
        "  t0 = time.time()\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  eval_loss, eval_accuracy = 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  for batch in validation_dataloader:\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask)\n",
        "    \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "    nb_eval_steps += 1\n",
        "  \n",
        "  print(\"   Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "  print(\"   Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "o24zXug4IoSi",
        "outputId": "f2e68c00-cc03-477d-cf25-507c24af1ca5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtKxYnRNgRUc"
      },
      "source": [
        "## **Predict dan Evaluate**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqfEXs3cNQLm",
        "outputId": "f670198d-930f-42c4-a49c-adba12c13b5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicting labels for 2,800 test sentences\n",
            " DONE.\n"
          ]
        }
      ],
      "source": [
        "print(\"Predicting labels for {:,} test sentences\".format(len(test_input)))\n",
        "\n",
        "model.eval()\n",
        "\n",
        "prediction, true_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask)\n",
        "    \n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "  prediction.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print(\" DONE.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alDDVf_ywJiA",
        "outputId": "6be2526f-5c66-4b55-cbd8-84b01328fbc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MCC: 0.633\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "flat_prediction = [item for sublist in prediction for item in sublist]\n",
        "flat_prediction = np.argmax(flat_prediction, axis=1).flatten()\n",
        "\n",
        "flat_true_labels = [item for sublist in true_labels for item in sublist]\n",
        "\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_prediction)\n",
        "\n",
        "print(\"MCC: %.3f\" %mcc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hSGk90kw8hQ",
        "outputId": "e98234cc-a639-450f-910f-6b5126fc16b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ACC: 0.847\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "acc = accuracy_score(flat_true_labels, flat_prediction)\n",
        "\n",
        "print(\"ACC: %.3f\" %acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsbQiZjDWAIK",
        "outputId": "b212022c-b5f7-49aa-e538-db86f9fdab15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RECALL: 0.820\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "recall = recall_score(flat_true_labels, flat_prediction)\n",
        "\n",
        "print(\"RECALL: %.3f\" %recall)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
